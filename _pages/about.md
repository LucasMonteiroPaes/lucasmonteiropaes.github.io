---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am an Applied Mathematics Ph.D. candidate at [Harvard University](https://www.seas.harvard.edu) SEAS working with Prof. [Flavio Calmon](http://people.seas.harvard.edu/~flavio/#) and a student researcher at [Google DeepMind](https://deepmind.google/) in the Gemini Safety Team. I use theoretical insights to develop safe and trustworthy AI and ML systems. My research is driven by the belief that AI and ML systems should not only be accurate and efficient but also transparent, fair, and aligned with human values and societal norms.

I firmly believe that theoretically guided methods can significantly outperform heuristics when designing safer AI systems. For this reason, my research focuses on answering questions such as: (i) "What is the optimal performance of a given method for designing safer AI?", (ii) "How can we achieve this optimal performance?", and (iii) "Can we relax the problem to achieve better performance beyond what is believed to be optimal?" My research is supported by the [2024 Apple Scholars in AI/ML](https://machinelearning.apple.com/updates/apple-scholars-aiml-2024) Fellowship.

Previously, I have also interned at [IBM Research](https://research.ibm.com/) in the IBM T.J. Watson Research Center. Before joining Harvard, I earned an M.S. in Computational Mathematics and Modeling from Instituto de Matemática Pura e Aplicada ([IMPA](https://impa.br/en_US/)), a beautiful mathematics institute in the [Tijuca National Park](https://en.wikipedia.org/wiki/Tijuca_National_Park) in Rio de Janeiro, Brazil. You can find my CV [here](https://drive.google.com/file/d/1UzeHBe4WfVejN_EvbH_Li31nOV6F_Ds2/view?usp=sharing).

## Recent papers
<span style="color: FireBrick"> 
April 2023 - Our [paper](https://dl.acm.org/doi/10.1145/3630106.3659036) was accepted at FAccT!
</span> \
<span style="font-size:15px">
In this multidisciplinary paper, we show the prevalence of arbitrary decisions in LLMs trained for content moderation and that these arbitrary decisions disproportionally affect underrepresented communities. Then, we discuss the implications of this finding on (i) freedom of speech, (ii) procedural fairness, and (iii) discrimination.
</span> 

<span style="color: FireBrick"> 
April 2023 - Our [paper](https://arxiv.org/abs/2312.03867) was published at the IEEE Journal on Selected Areas in Information Theory. 
</span> \
<span style="font-size:15px">
We introduce CVaR fairness, a metric that allows ML practitioners to detect performance disparities across a large number of demographic groups (e.g., all combinations of race, sex, and nationality) with theoretical guarantees.
</span> 

<span style="color: FireBrick"> 
April 2023 - Our [paper](https://ieeexplore.ieee.org/document/10206657) was accepted at ISIT 2023.
</span> \
<span style="font-size:15px">
Rashomon effect is the phenomenon where different models achieve the similar permormance but provide different predictions for certain input points.
We show that the Rashomon effect is inevitable and provide a method for practitioners to select the Rashomon parameter as a function of the dataset size. 
</span> 

<span style="color: FireBrick"> 
January 2023 - Our [paper](https://ojs.aaai.org/index.php/AAAI/article/view/26837) received the Innovative Applications of AI award from AAAI. 
</span> \
<span style="font-size:15px"> 
In this paper, we developed an ML solution that combines deep learning and conformal prediction to output fast and accurate volume estimates and segmentation masks from fetal MRI. The proposed solution in the paper was deployed by the biggest clinical diagnosis company in Latin America.
</span> 

<span style="color: FireBrick"> 
August 2022 - Our [paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/0cfc9404f89400c5ed897035e0d3748c-Abstract-Conference.html) was accepted at NeurIPS 2022. 
</span> \
<span style="font-size:15px"> 
This paper aims to understand the conditions under which one can detect fair use violations in predictive models and, more interestingly, the conditions where estimating fair use is impossible.
</span> 


## Recent announcements
<span style="color: FireBrick"> 
March 2024 - I am happy to announce that I am joining [Google DeepMind](https://deepmind.google/) as a student researcher!
</span> 

<span style="color: FireBrick"> 
March 2024 - I am thrilled to announce that I was selected as an [Apple Scholar](https://machinelearning.apple.com/updates/apple-scholars-aiml-2024)!
</span> 

<span style="color: FireBrick"> 
May 2023 - I am happy to announce that I am joining [IBM Research](https://research.ibm.com) for the summer. 
</span> 

<span style="color: FireBrick"> 
August 2023 - I received the ISIT Student Travel Grant. 
</span> 

<span style="color: FireBrick"> 
August 2022 - I received the NeurIPS scholar award. 
</span> 

<span style="color: FireBrick"> 
July 2022 - I received the [Fundação Estudar](https://www.estudar.org.br) Leadership Fellowship. 
</span> \
<span style="font-size:15px"> 
The Fellowship aims to support, bring together, and develop Brazil's most promising young leaders that can generate positive transformations in their sector of activity. I was one of the 30 fellows selected out of 33k **(0.08% selected)**. 
</span> 


